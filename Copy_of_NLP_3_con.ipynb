{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAu1GNQvwNR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49f472a0-5e23-413b-ca57-23fbf3109026"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "nltk.download()\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import LancasterStemmer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> all\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "    Downloading collection 'all'\n",
            "       | \n",
            "       | Downloading package abc to /root/nltk_data...\n",
            "       |   Package abc is already up-to-date!\n",
            "       | Downloading package alpino to /root/nltk_data...\n",
            "       |   Package alpino is already up-to-date!\n",
            "       | Downloading package averaged_perceptron_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package averaged_perceptron_tagger is already up-to-date!\n",
            "       | Downloading package averaged_perceptron_tagger_ru to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package averaged_perceptron_tagger_ru is already up-to-\n",
            "       |       date!\n",
            "       | Downloading package basque_grammars to /root/nltk_data...\n",
            "       |   Package basque_grammars is already up-to-date!\n",
            "       | Downloading package biocreative_ppi to /root/nltk_data...\n",
            "       |   Package biocreative_ppi is already up-to-date!\n",
            "       | Downloading package bllip_wsj_no_aux to /root/nltk_data...\n",
            "       |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "       | Downloading package book_grammars to /root/nltk_data...\n",
            "       |   Package book_grammars is already up-to-date!\n",
            "       | Downloading package brown to /root/nltk_data...\n",
            "       |   Package brown is already up-to-date!\n",
            "       | Downloading package brown_tei to /root/nltk_data...\n",
            "       |   Package brown_tei is already up-to-date!\n",
            "       | Downloading package cess_cat to /root/nltk_data...\n",
            "       |   Package cess_cat is already up-to-date!\n",
            "       | Downloading package cess_esp to /root/nltk_data...\n",
            "       |   Package cess_esp is already up-to-date!\n",
            "       | Downloading package chat80 to /root/nltk_data...\n",
            "       |   Package chat80 is already up-to-date!\n",
            "       | Downloading package city_database to /root/nltk_data...\n",
            "       |   Package city_database is already up-to-date!\n",
            "       | Downloading package cmudict to /root/nltk_data...\n",
            "       |   Package cmudict is already up-to-date!\n",
            "       | Downloading package comparative_sentences to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package comparative_sentences is already up-to-date!\n",
            "       | Downloading package comtrans to /root/nltk_data...\n",
            "       |   Package comtrans is already up-to-date!\n",
            "       | Downloading package conll2000 to /root/nltk_data...\n",
            "       |   Package conll2000 is already up-to-date!\n",
            "       | Downloading package conll2002 to /root/nltk_data...\n",
            "       |   Package conll2002 is already up-to-date!\n",
            "       | Downloading package conll2007 to /root/nltk_data...\n",
            "       |   Package conll2007 is already up-to-date!\n",
            "       | Downloading package crubadan to /root/nltk_data...\n",
            "       |   Package crubadan is already up-to-date!\n",
            "       | Downloading package dependency_treebank to /root/nltk_data...\n",
            "       |   Package dependency_treebank is already up-to-date!\n",
            "       | Downloading package dolch to /root/nltk_data...\n",
            "       |   Package dolch is already up-to-date!\n",
            "       | Downloading package europarl_raw to /root/nltk_data...\n",
            "       |   Package europarl_raw is already up-to-date!\n",
            "       | Downloading package extended_omw to /root/nltk_data...\n",
            "       |   Package extended_omw is already up-to-date!\n",
            "       | Downloading package floresta to /root/nltk_data...\n",
            "       |   Package floresta is already up-to-date!\n",
            "       | Downloading package framenet_v15 to /root/nltk_data...\n",
            "       |   Package framenet_v15 is already up-to-date!\n",
            "       | Downloading package framenet_v17 to /root/nltk_data...\n",
            "       |   Package framenet_v17 is already up-to-date!\n",
            "       | Downloading package gazetteers to /root/nltk_data...\n",
            "       |   Package gazetteers is already up-to-date!\n",
            "       | Downloading package genesis to /root/nltk_data...\n",
            "       |   Package genesis is already up-to-date!\n",
            "       | Downloading package gutenberg to /root/nltk_data...\n",
            "       |   Package gutenberg is already up-to-date!\n",
            "       | Downloading package ieer to /root/nltk_data...\n",
            "       |   Package ieer is already up-to-date!\n",
            "       | Downloading package inaugural to /root/nltk_data...\n",
            "       |   Package inaugural is already up-to-date!\n",
            "       | Downloading package indian to /root/nltk_data...\n",
            "       |   Package indian is already up-to-date!\n",
            "       | Downloading package jeita to /root/nltk_data...\n",
            "       |   Package jeita is already up-to-date!\n",
            "       | Downloading package kimmo to /root/nltk_data...\n",
            "       |   Package kimmo is already up-to-date!\n",
            "       | Downloading package knbc to /root/nltk_data...\n",
            "       |   Package knbc is already up-to-date!\n",
            "       | Downloading package large_grammars to /root/nltk_data...\n",
            "       |   Package large_grammars is already up-to-date!\n",
            "       | Downloading package lin_thesaurus to /root/nltk_data...\n",
            "       |   Package lin_thesaurus is already up-to-date!\n",
            "       | Downloading package mac_morpho to /root/nltk_data...\n",
            "       |   Package mac_morpho is already up-to-date!\n",
            "       | Downloading package machado to /root/nltk_data...\n",
            "       |   Package machado is already up-to-date!\n",
            "       | Downloading package masc_tagged to /root/nltk_data...\n",
            "       |   Package masc_tagged is already up-to-date!\n",
            "       | Downloading package maxent_ne_chunker to /root/nltk_data...\n",
            "       |   Package maxent_ne_chunker is already up-to-date!\n",
            "       | Downloading package maxent_treebank_pos_tagger to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package maxent_treebank_pos_tagger is already up-to-date!\n",
            "       | Downloading package moses_sample to /root/nltk_data...\n",
            "       |   Package moses_sample is already up-to-date!\n",
            "       | Downloading package movie_reviews to /root/nltk_data...\n",
            "       |   Package movie_reviews is already up-to-date!\n",
            "       | Downloading package mte_teip5 to /root/nltk_data...\n",
            "       |   Package mte_teip5 is already up-to-date!\n",
            "       | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "       |   Package mwa_ppdb is already up-to-date!\n",
            "       | Downloading package names to /root/nltk_data...\n",
            "       |   Package names is already up-to-date!\n",
            "       | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "       |   Package nombank.1.0 is already up-to-date!\n",
            "       | Downloading package nonbreaking_prefixes to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package nonbreaking_prefixes is already up-to-date!\n",
            "       | Downloading package nps_chat to /root/nltk_data...\n",
            "       |   Package nps_chat is already up-to-date!\n",
            "       | Downloading package omw to /root/nltk_data...\n",
            "       |   Package omw is already up-to-date!\n",
            "       | Downloading package omw-1.4 to /root/nltk_data...\n",
            "       |   Package omw-1.4 is already up-to-date!\n",
            "       | Downloading package opinion_lexicon to /root/nltk_data...\n",
            "       |   Package opinion_lexicon is already up-to-date!\n",
            "       | Downloading package panlex_swadesh to /root/nltk_data...\n",
            "       |   Package panlex_swadesh is already up-to-date!\n",
            "       | Downloading package paradigms to /root/nltk_data...\n",
            "       |   Package paradigms is already up-to-date!\n",
            "       | Downloading package pe08 to /root/nltk_data...\n",
            "       |   Package pe08 is already up-to-date!\n",
            "       | Downloading package perluniprops to /root/nltk_data...\n",
            "       |   Package perluniprops is already up-to-date!\n",
            "       | Downloading package pil to /root/nltk_data...\n",
            "       |   Package pil is already up-to-date!\n",
            "       | Downloading package pl196x to /root/nltk_data...\n",
            "       |   Package pl196x is already up-to-date!\n",
            "       | Downloading package porter_test to /root/nltk_data...\n",
            "       |   Package porter_test is already up-to-date!\n",
            "       | Downloading package ppattach to /root/nltk_data...\n",
            "       |   Package ppattach is already up-to-date!\n",
            "       | Downloading package problem_reports to /root/nltk_data...\n",
            "       |   Package problem_reports is already up-to-date!\n",
            "       | Downloading package product_reviews_1 to /root/nltk_data...\n",
            "       |   Package product_reviews_1 is already up-to-date!\n",
            "       | Downloading package product_reviews_2 to /root/nltk_data...\n",
            "       |   Package product_reviews_2 is already up-to-date!\n",
            "       | Downloading package propbank to /root/nltk_data...\n",
            "       |   Package propbank is already up-to-date!\n",
            "       | Downloading package pros_cons to /root/nltk_data...\n",
            "       |   Package pros_cons is already up-to-date!\n",
            "       | Downloading package ptb to /root/nltk_data...\n",
            "       |   Package ptb is already up-to-date!\n",
            "       | Downloading package punkt to /root/nltk_data...\n",
            "       |   Package punkt is already up-to-date!\n",
            "       | Downloading package qc to /root/nltk_data...\n",
            "       |   Package qc is already up-to-date!\n",
            "       | Downloading package reuters to /root/nltk_data...\n",
            "       |   Package reuters is already up-to-date!\n",
            "       | Downloading package rslp to /root/nltk_data...\n",
            "       |   Package rslp is already up-to-date!\n",
            "       | Downloading package rte to /root/nltk_data...\n",
            "       |   Package rte is already up-to-date!\n",
            "       | Downloading package sample_grammars to /root/nltk_data...\n",
            "       |   Package sample_grammars is already up-to-date!\n",
            "       | Downloading package semcor to /root/nltk_data...\n",
            "       |   Package semcor is already up-to-date!\n",
            "       | Downloading package senseval to /root/nltk_data...\n",
            "       |   Package senseval is already up-to-date!\n",
            "       | Downloading package sentence_polarity to /root/nltk_data...\n",
            "       |   Package sentence_polarity is already up-to-date!\n",
            "       | Downloading package sentiwordnet to /root/nltk_data...\n",
            "       |   Package sentiwordnet is already up-to-date!\n",
            "       | Downloading package shakespeare to /root/nltk_data...\n",
            "       |   Package shakespeare is already up-to-date!\n",
            "       | Downloading package sinica_treebank to /root/nltk_data...\n",
            "       |   Package sinica_treebank is already up-to-date!\n",
            "       | Downloading package smultron to /root/nltk_data...\n",
            "       |   Package smultron is already up-to-date!\n",
            "       | Downloading package snowball_data to /root/nltk_data...\n",
            "       |   Package snowball_data is already up-to-date!\n",
            "       | Downloading package spanish_grammars to /root/nltk_data...\n",
            "       |   Package spanish_grammars is already up-to-date!\n",
            "       | Downloading package state_union to /root/nltk_data...\n",
            "       |   Package state_union is already up-to-date!\n",
            "       | Downloading package stopwords to /root/nltk_data...\n",
            "       |   Package stopwords is already up-to-date!\n",
            "       | Downloading package subjectivity to /root/nltk_data...\n",
            "       |   Package subjectivity is already up-to-date!\n",
            "       | Downloading package swadesh to /root/nltk_data...\n",
            "       |   Package swadesh is already up-to-date!\n",
            "       | Downloading package switchboard to /root/nltk_data...\n",
            "       |   Package switchboard is already up-to-date!\n",
            "       | Downloading package tagsets to /root/nltk_data...\n",
            "       |   Package tagsets is already up-to-date!\n",
            "       | Downloading package timit to /root/nltk_data...\n",
            "       |   Package timit is already up-to-date!\n",
            "       | Downloading package toolbox to /root/nltk_data...\n",
            "       |   Package toolbox is already up-to-date!\n",
            "       | Downloading package treebank to /root/nltk_data...\n",
            "       |   Package treebank is already up-to-date!\n",
            "       | Downloading package twitter_samples to /root/nltk_data...\n",
            "       |   Package twitter_samples is already up-to-date!\n",
            "       | Downloading package udhr to /root/nltk_data...\n",
            "       |   Package udhr is already up-to-date!\n",
            "       | Downloading package udhr2 to /root/nltk_data...\n",
            "       |   Package udhr2 is already up-to-date!\n",
            "       | Downloading package unicode_samples to /root/nltk_data...\n",
            "       |   Package unicode_samples is already up-to-date!\n",
            "       | Downloading package universal_tagset to /root/nltk_data...\n",
            "       |   Package universal_tagset is already up-to-date!\n",
            "       | Downloading package universal_treebanks_v20 to\n",
            "       |     /root/nltk_data...\n",
            "       |   Package universal_treebanks_v20 is already up-to-date!\n",
            "       | Downloading package vader_lexicon to /root/nltk_data...\n",
            "       |   Package vader_lexicon is already up-to-date!\n",
            "       | Downloading package verbnet to /root/nltk_data...\n",
            "       |   Package verbnet is already up-to-date!\n",
            "       | Downloading package verbnet3 to /root/nltk_data...\n",
            "       |   Package verbnet3 is already up-to-date!\n",
            "       | Downloading package webtext to /root/nltk_data...\n",
            "       |   Package webtext is already up-to-date!\n",
            "       | Downloading package wmt15_eval to /root/nltk_data...\n",
            "       |   Package wmt15_eval is already up-to-date!\n",
            "       | Downloading package word2vec_sample to /root/nltk_data...\n",
            "       |   Package word2vec_sample is already up-to-date!\n",
            "       | Downloading package wordnet to /root/nltk_data...\n",
            "       |   Package wordnet is already up-to-date!\n",
            "       | Downloading package wordnet2021 to /root/nltk_data...\n",
            "       |   Package wordnet2021 is already up-to-date!\n",
            "       | Downloading package wordnet31 to /root/nltk_data...\n",
            "       |   Package wordnet31 is already up-to-date!\n",
            "       | Downloading package wordnet_ic to /root/nltk_data...\n",
            "       |   Package wordnet_ic is already up-to-date!\n",
            "       | Downloading package words to /root/nltk_data...\n",
            "       |   Package words is already up-to-date!\n",
            "       | Downloading package ycoe to /root/nltk_data...\n",
            "       |   Package ycoe is already up-to-date!\n",
            "       | \n",
            "     Done downloading collection all\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjykdabKwl6w",
        "outputId": "60a5b739-95ef-48da-c026-e622a1d61d9e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "GrWKHY3hwsgu",
        "outputId": "665bae4f-bf88-4854-d478-2e1f1a9246c8"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/NLP datasets/Consumer_Complaints_big.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (5,6,11,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Date received                                            Product  \\\n",
              "0    07/17/2019  Credit reporting, credit repair services, or o...   \n",
              "1    07/17/2019                        Credit card or prepaid card   \n",
              "2    07/17/2019                                    Debt collection   \n",
              "3    07/17/2019                                           Mortgage   \n",
              "4    07/17/2019                                    Debt collection   \n",
              "\n",
              "                    Sub-product  \\\n",
              "0              Credit reporting   \n",
              "1  General-purpose prepaid card   \n",
              "2                    Other debt   \n",
              "3                   VA mortgage   \n",
              "4                    Other debt   \n",
              "\n",
              "                                               Issue  \\\n",
              "0               Incorrect information on your report   \n",
              "1                             Trouble using the card   \n",
              "2  Took or threatened to take negative or legal a...   \n",
              "3                     Trouble during payment process   \n",
              "4                  Attempts to collect debt not owed   \n",
              "\n",
              "                                           Sub-issue  \\\n",
              "0                           Account status incorrect   \n",
              "1  Problem using the card to withdraw money from ...   \n",
              "2  Threatened or suggested your credit would be d...   \n",
              "3                                                NaN   \n",
              "4                                  Debt is not yours   \n",
              "\n",
              "  Consumer complaint narrative  \\\n",
              "0                          NaN   \n",
              "1                          NaN   \n",
              "2                          NaN   \n",
              "3                          NaN   \n",
              "4                          NaN   \n",
              "\n",
              "                             Company public response  \\\n",
              "0                                                NaN   \n",
              "1                                                NaN   \n",
              "2                                                NaN   \n",
              "3                                                NaN   \n",
              "4  Company believes it acted appropriately as aut...   \n",
              "\n",
              "                         Company State ZIP code           Tags  \\\n",
              "0            ALLY FINANCIAL INC.    TX    75035            NaN   \n",
              "1                     SQUARE INC    KS    674XX            NaN   \n",
              "2  Diversified Consultants, Inc.    FL      NaN            NaN   \n",
              "3             FLAGSTAR BANK, FSB    VA    22554  Servicemember   \n",
              "4        BYL Collection Services    TN    370XX  Servicemember   \n",
              "\n",
              "  Consumer consent provided? Submitted via Date sent to company  \\\n",
              "0                        NaN           Web           07/17/2019   \n",
              "1                        NaN           Web           07/17/2019   \n",
              "2                        NaN           Web           07/17/2019   \n",
              "3                        NaN           Web           07/17/2019   \n",
              "4                        NaN           Web           07/17/2019   \n",
              "\n",
              "  Company response to consumer Timely response? Consumer disputed?  \\\n",
              "0                  In progress              Yes                NaN   \n",
              "1                  In progress              Yes                NaN   \n",
              "2                  In progress              Yes                NaN   \n",
              "3                  In progress              Yes                NaN   \n",
              "4      Closed with explanation              Yes                NaN   \n",
              "\n",
              "   Complaint ID  \n",
              "0       3309495  \n",
              "1       3310031  \n",
              "2       3309687  \n",
              "3       3308925  \n",
              "4       3308914  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b7a9765d-80ed-4265-a4b2-10a578355913\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date received</th>\n",
              "      <th>Product</th>\n",
              "      <th>Sub-product</th>\n",
              "      <th>Issue</th>\n",
              "      <th>Sub-issue</th>\n",
              "      <th>Consumer complaint narrative</th>\n",
              "      <th>Company public response</th>\n",
              "      <th>Company</th>\n",
              "      <th>State</th>\n",
              "      <th>ZIP code</th>\n",
              "      <th>Tags</th>\n",
              "      <th>Consumer consent provided?</th>\n",
              "      <th>Submitted via</th>\n",
              "      <th>Date sent to company</th>\n",
              "      <th>Company response to consumer</th>\n",
              "      <th>Timely response?</th>\n",
              "      <th>Consumer disputed?</th>\n",
              "      <th>Complaint ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>07/17/2019</td>\n",
              "      <td>Credit reporting, credit repair services, or o...</td>\n",
              "      <td>Credit reporting</td>\n",
              "      <td>Incorrect information on your report</td>\n",
              "      <td>Account status incorrect</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ALLY FINANCIAL INC.</td>\n",
              "      <td>TX</td>\n",
              "      <td>75035</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Web</td>\n",
              "      <td>07/17/2019</td>\n",
              "      <td>In progress</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3309495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>07/17/2019</td>\n",
              "      <td>Credit card or prepaid card</td>\n",
              "      <td>General-purpose prepaid card</td>\n",
              "      <td>Trouble using the card</td>\n",
              "      <td>Problem using the card to withdraw money from ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SQUARE INC</td>\n",
              "      <td>KS</td>\n",
              "      <td>674XX</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Web</td>\n",
              "      <td>07/17/2019</td>\n",
              "      <td>In progress</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3310031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>07/17/2019</td>\n",
              "      <td>Debt collection</td>\n",
              "      <td>Other debt</td>\n",
              "      <td>Took or threatened to take negative or legal a...</td>\n",
              "      <td>Threatened or suggested your credit would be d...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Diversified Consultants, Inc.</td>\n",
              "      <td>FL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Web</td>\n",
              "      <td>07/17/2019</td>\n",
              "      <td>In progress</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3309687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>07/17/2019</td>\n",
              "      <td>Mortgage</td>\n",
              "      <td>VA mortgage</td>\n",
              "      <td>Trouble during payment process</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FLAGSTAR BANK, FSB</td>\n",
              "      <td>VA</td>\n",
              "      <td>22554</td>\n",
              "      <td>Servicemember</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Web</td>\n",
              "      <td>07/17/2019</td>\n",
              "      <td>In progress</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3308925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>07/17/2019</td>\n",
              "      <td>Debt collection</td>\n",
              "      <td>Other debt</td>\n",
              "      <td>Attempts to collect debt not owed</td>\n",
              "      <td>Debt is not yours</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Company believes it acted appropriately as aut...</td>\n",
              "      <td>BYL Collection Services</td>\n",
              "      <td>TN</td>\n",
              "      <td>370XX</td>\n",
              "      <td>Servicemember</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Web</td>\n",
              "      <td>07/17/2019</td>\n",
              "      <td>Closed with explanation</td>\n",
              "      <td>Yes</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3308914</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b7a9765d-80ed-4265-a4b2-10a578355913')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b7a9765d-80ed-4265-a4b2-10a578355913 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b7a9765d-80ed-4265-a4b2-10a578355913');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frQLMPDQdLvz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be17050b-7b79-4e86-a5e0-f780dab1caf8"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1334876, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV42YgOBw7P0"
      },
      "source": [
        "df1 = df[['Product','Consumer complaint narrative']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puAqJ_L6xA2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57213812-c1ec-4713-f82f-080ad67761f7"
      },
      "source": [
        "df1['Product'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Mortgage                                                                        282345\n",
              "Debt collection                                                                 253853\n",
              "Credit reporting, credit repair services, or other personal consumer reports    252092\n",
              "Credit reporting                                                                140432\n",
              "Credit card                                                                      89190\n",
              "Bank account or service                                                          86206\n",
              "Student loan                                                                     52889\n",
              "Credit card or prepaid card                                                      52468\n",
              "Checking or savings account                                                      45000\n",
              "Consumer Loan                                                                    31604\n",
              "Vehicle loan or lease                                                            12408\n",
              "Money transfer, virtual currency, or money service                               11184\n",
              "Payday loan, title loan, or personal loan                                         9411\n",
              "Payday loan                                                                       5544\n",
              "Money transfers                                                                   5354\n",
              "Prepaid card                                                                      3819\n",
              "Other financial service                                                           1059\n",
              "Virtual currency                                                                    18\n",
              "Name: Product, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFQDSewjxEkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c64e9a5e-66e3-41bb-f26f-5e20d5ffd6b6"
      },
      "source": [
        "df1['Product'] = df1['Product'].str.lower()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZBXJ7yyxyzg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a7ce466-a419-41d2-f60a-eb9456c705b9"
      },
      "source": [
        "df1.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Product                              0\n",
              "Consumer complaint narrative    938347\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOCXfDl-Z71f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bca0545-a580-4e0a-a7fe-273ba61ef7fc"
      },
      "source": [
        "df1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1334876, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PaEWi1Sfx1El"
      },
      "source": [
        "df1= df1.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "id": "HUf9rLXgHYtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57163ec4-c909-4dcb-bb0f-4949021886a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(396529, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H7ZySGSx6A6"
      },
      "source": [
        "def renaming(x):\n",
        "   #print(x)\n",
        "   if x =='credit reporting':\n",
        "        x = 'credit reporting, credit repair services, or other personal consumer reports'\n",
        "   elif x == 'credit card':\n",
        "        x = 'credit card or prepaid card'\n",
        "   elif x == 'virtual currency':\n",
        "        x = 'money transfer, virtual currency, or money service'\n",
        "   elif x == 'prepaid card':\n",
        "        x = 'credit card or prepaid card'\n",
        "   elif x == 'money transfers':\n",
        "        x = 'money transfer, virtual currency, or money service'\n",
        "   elif x == 'student loan': \n",
        "        x='Loans'\n",
        "   elif x=='consumer loan': \n",
        "        x='Loans'\n",
        "   elif x=='payday loan': \n",
        "        x='Loans'\n",
        "   elif x=='checking or savings account': \n",
        "        x='bank account or service'\n",
        "   elif x=='payday loan, title loan, or personal loan': \n",
        "        x='Loans'\n",
        "   elif x=='vehicle loan or lease': \n",
        "        x='Loans'\n",
        "   return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Hb6PLIx8ZJ"
      },
      "source": [
        "df1['Product'] = df1['Product'].apply(renaming)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPX49m3mbWMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55de03fa-fa81-4527-dcb9-4976d206ec3f"
      },
      "source": [
        "df1['Product'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "credit reporting, credit repair services, or other personal consumer reports    129418\n",
              "debt collection                                                                  89379\n",
              "mortgage                                                                         54109\n",
              "Loans                                                                            44409\n",
              "credit card or prepaid card                                                      43103\n",
              "bank account or service                                                          28554\n",
              "money transfer, virtual currency, or money service                                7265\n",
              "other financial service                                                            292\n",
              "Name: Product, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YmvTJ1A6x-5c"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df1['Product'] = le.fit_transform(df1['Product'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPrUMI1HbpC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96b40abe-511c-42fd-f0ef-60b64ef1684c"
      },
      "source": [
        "value_counts = df1['Product'].value_counts()\n",
        "value_counts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    129418\n",
              "4     89379\n",
              "6     54109\n",
              "0     44409\n",
              "2     43103\n",
              "1     28554\n",
              "5      7265\n",
              "7       292\n",
              "Name: Product, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhFL8I7QyBB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1532ecf8-7b0d-4d8f-e524-e691428610e2"
      },
      "source": [
        "df1 = df1[~df1['Product'].isin(value_counts[value_counts<10000].index)]\n",
        "df1['Product'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    129418\n",
              "4     89379\n",
              "6     54109\n",
              "0     44409\n",
              "2     43103\n",
              "1     28554\n",
              "Name: Product, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtFbAXB2yDC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14980b4-c4bc-423a-efa8-ac85294d3911"
      },
      "source": [
        "# from string import punctuation\n",
        "# from nltk.corpus import stopwords\n",
        "stuff_to_be_removed = list(stopwords.words('english'))+list(punctuation)\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import LancasterStemmer\n",
        "stemmer = LancasterStemmer()\n",
        "corpus = df1['Consumer complaint narrative'].tolist()\n",
        "len(corpus)\n",
        "corpus = corpus[1:10000]\n",
        "print(corpus[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When they call they dont answer the call and they call all day long. I havent sign any contact with this company I never had any comunicacin with agency! I never sign any contract or made any commitment with Maury Cobb & Associates! As a consumer by the law on the credit company if I did not sign any contact with this collect this need to be removed from my XXXX report!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf2j4_Q2yFAt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3452aaab-18e3-44b4-e153-48122dcbe594"
      },
      "source": [
        "final_corpus = []\n",
        "for i in range(len(corpus)):\n",
        "  word = word_tokenize(corpus[i].lower())\n",
        "  word = [stemmer.stem(y) for y in word if y not in stuff_to_be_removed]\n",
        "  j = \" \".join(word)\n",
        "  final_corpus.append(j)\n",
        "final_corpus[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cal dont answ cal cal day long hav sign contact company nev comunicacin ag nev sign contract mad commit maury cob assocy consum law credit company sign contact collect nee remov xxxx report'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvff_hmOyHGy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "004e390b-e8bf-4811-9600-faf8f645855b"
      },
      "source": [
        "product_list=df1['Product'].tolist()\n",
        "product_list=product_list[1:10000]\n",
        "newdf = pd.DataFrame(final_corpus)\n",
        "newdf['label'] = product_list\n",
        "newdf.columns=['sentence','label']\n",
        "newdf.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            sentence  label\n",
              "0                                      16000.00 debt      3\n",
              "1  cal dont answ cal cal day long hav sign contac...      4\n",
              "2  provid account inform show debt paid credit ka...      4\n",
              "3  2 charg credit report collect ag `` trid asset...      4\n",
              "4  xxxx xxxx xxxx xxxx post 3 collect account 3 c...      3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11748f2b-145a-48cc-8b55-0ae6bc6dc23e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16000.00 debt</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>cal dont answ cal cal day long hav sign contac...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>provid account inform show debt paid credit ka...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2 charg credit report collect ag `` trid asset...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>xxxx xxxx xxxx xxxx post 3 collect account 3 c...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11748f2b-145a-48cc-8b55-0ae6bc6dc23e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11748f2b-145a-48cc-8b55-0ae6bc6dc23e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11748f2b-145a-48cc-8b55-0ae6bc6dc23e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKI3MK_tyXfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5d200f-693e-47d6-a06a-068f65506613"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "tfidf = TfidfVectorizer()\n",
        "vector = tfidf.fit_transform(newdf['sentence'])\n",
        "print(type(vector))\n",
        "x_train = vector.toarray()\n",
        "print(x_train)\n",
        "y_train= newdf['label']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'scipy.sparse.csr.csr_matrix'>\n",
            "[[0.27715548 0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.20051905 0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.05226919 0.         0.         ... 0.         0.         0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BvgH3DLyaIy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79816b6c-25b2-4c3d-972a-0b15cd0e42d8"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "ab = MultinomialNB()\n",
        "ab.fit(x_train,y_train)\n",
        "ypred = ab.predict(x_train)\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "print(accuracy_score(y_train,ypred))\n",
        "print(confusion_matrix(y_train,ypred))\n",
        "print(classification_report(y_train,ypred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6332633263326333\n",
            "[[ 258    0    3  627  113    0]\n",
            " [   0   38   63  467   34    0]\n",
            " [   0    0  261  807   43    0]\n",
            " [   0    3    0 3971   73    1]\n",
            " [   3    0    3  835 1549    1]\n",
            " [   5    0    0  540   46  255]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.26      0.41      1001\n",
            "           1       0.93      0.06      0.12       602\n",
            "           2       0.79      0.23      0.36      1111\n",
            "           3       0.55      0.98      0.70      4048\n",
            "           4       0.83      0.65      0.73      2391\n",
            "           6       0.99      0.30      0.46       846\n",
            "\n",
            "    accuracy                           0.63      9999\n",
            "   macro avg       0.84      0.41      0.46      9999\n",
            "weighted avg       0.75      0.63      0.59      9999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yBS8AwBHj1_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc1a9054-f95a-4a1c-a1d3-5291aee10da3"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dtree_model = DecisionTreeClassifier(max_depth = 25)\n",
        "dtree_model.fit(x_train, y_train)\n",
        "ypred2 = dtree_model.predict(x_train)\n",
        "print(accuracy_score(y_train,ypred2))\n",
        "print(classification_report(y_train,ypred2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9526952695269527\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95      1001\n",
            "           1       0.96      0.93      0.94       602\n",
            "           2       0.94      0.93      0.93      1111\n",
            "           3       0.94      0.98      0.96      4048\n",
            "           4       0.96      0.93      0.95      2391\n",
            "           6       0.99      0.94      0.96       846\n",
            "\n",
            "    accuracy                           0.95      9999\n",
            "   macro avg       0.96      0.94      0.95      9999\n",
            "weighted avg       0.95      0.95      0.95      9999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors = 7)\n",
        "knn.fit(x_train, y_train)\n",
        "ypred4 = knn.predict(x_train)\n",
        "print(accuracy_score(y_train,ypred4))\n",
        "print(classification_report(y_train,ypred4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxMEvN46HJ3c",
        "outputId": "4aae5e7c-ac54-4742-8401-21dc76a2c38d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7815781578157815\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.66      0.72      1001\n",
            "           1       0.78      0.73      0.76       602\n",
            "           2       0.76      0.71      0.74      1111\n",
            "           3       0.74      0.93      0.82      4048\n",
            "           4       0.85      0.67      0.75      2391\n",
            "           6       0.90      0.68      0.78       846\n",
            "\n",
            "    accuracy                           0.78      9999\n",
            "   macro avg       0.81      0.73      0.76      9999\n",
            "weighted avg       0.79      0.78      0.78      9999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rdforest = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)\n",
        "rdforest.fit(x_train, y_train)\n",
        "ypred5 = rdforest.predict(x_train)\n",
        "print(accuracy_score(y_train,ypred5))\n",
        "print(classification_report(y_train,ypred5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boQMRLLWIYDM",
        "outputId": "6b2d1e62-a0fe-4aea-b572-9dcaf8406da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9956995699569957\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1001\n",
            "           1       1.00      1.00      1.00       602\n",
            "           2       0.99      0.99      0.99      1111\n",
            "           3       1.00      1.00      1.00      4048\n",
            "           4       1.00      0.99      1.00      2391\n",
            "           6       1.00      0.99      0.99       846\n",
            "\n",
            "    accuracy                           1.00      9999\n",
            "   macro avg       1.00      0.99      1.00      9999\n",
            "weighted avg       1.00      1.00      1.00      9999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "lin_clf = svm.LinearSVC()\n",
        "lin_clf.fit(x_train, y_train)\n",
        "ypred3 = lin_clf.predict(x_train)\n",
        "print(accuracy_score(y_train,ypred3))\n",
        "print(classification_report(y_train,ypred3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oed5HDBUI2XS",
        "outputId": "0de21db2-5cb4-438b-f2ad-b51783bba449"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.953995399539954\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.93      0.94      1001\n",
            "           1       0.97      0.99      0.98       602\n",
            "           2       0.96      0.95      0.95      1111\n",
            "           3       0.96      0.96      0.96      4048\n",
            "           4       0.94      0.94      0.94      2391\n",
            "           6       0.98      0.98      0.98       846\n",
            "\n",
            "    accuracy                           0.95      9999\n",
            "   macro avg       0.96      0.96      0.96      9999\n",
            "weighted avg       0.95      0.95      0.95      9999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "xgb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
        "xgb.fit(x_train, y_train)\n",
        "ypred6 = xgb.predict(x_train)\n",
        "print(accuracy_score(y_train,ypred6))\n",
        "print(classification_report(y_train,ypred6))"
      ],
      "metadata": {
        "id": "QFeg_ru4LRtV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "outputId": "94dfe2ed-5825-4378-ad71-4d9f4d5ea919"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-de5612cd5f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mxgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mypred6\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mypred6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    594\u001b[0m             \u001b[0msample_weight_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0mbegin_at_stage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m             \u001b[0mmonitor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m         )\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    670\u001b[0m                 \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mX_csc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                 \u001b[0mX_csr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m             )\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m             \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresidual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1320\u001b[0;31m             \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1321\u001b[0m         )\n\u001b[1;32m   1322\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xfnw036dNX43"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}